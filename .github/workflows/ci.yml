name: CI

on:
  pull_request:
    types: [opened, synchronize, reopened, labeled, unlabeled]
    branches: ['main']
  push:
    branches: ['main']

env:
  # Node and Package Management
  NODE_VERSION: 'latest'
  NPM_VERSION: 'latest'
  WRANGLER_VERSION: '3.28.2'

  # Site Configuration - Use secrets for actual values
  SITE_URL: ${{ secrets.SITE_URL }}
  PROJECT_NAME: 'blog-radaideh-info'
  CUSTOM_DOMAIN: ${{ secrets.CUSTOM_DOMAIN }}
  DIST_DIR: './dist'

  # Development Configuration
  DEV_URL: 'http://localhost:4321'
  DEV_PORT: '4321'

  # Deployment Configuration
  DEPLOYMENT_ENV: 'production'
  BUILD_ENV: 'production'

  # Giscus Configuration - Use secrets for actual values
  GISCUS_REPO: ${{ secrets.GISCUS_REPO }}
  GISCUS_REPO_ID: ${{ secrets.GISCUS_REPO_ID }}
  GISCUS_CATEGORY: ${{ secrets.GISCUS_CATEGORY }}
  GISCUS_CATEGORY_ID: ${{ secrets.GISCUS_CATEGORY_ID }}

  # KV Namespace Names
  KV_STATS_NAME: 'BLOG_STATS'
  KV_VIEWS_NAME: 'BLOG_VIEWS'
  KV_REACTIONS_NAME: 'BLOG_REACTIONS'

  # Rate Limiting Configuration
  RATE_LIMIT_REQUESTS: '60'
  RATE_LIMIT_WINDOW: '60'

permissions:
  contents: write
  pull-requests: write
  issues: write
  deployments: write
  discussions: write
  actions: write

concurrency:
  group: ${{ github.workflow }}-${{ github.event.pull_request.number || github.ref }}
  cancel-in-progress: true

jobs:
  # Combined job: Quality checks + Build + Tests (runs once, caches everything)
  build-and-test:
    runs-on: ubuntu-latest
    if: |
      contains(github.event.pull_request.labels.*.name, 'ready-to-test') || 
      contains(github.event.pull_request.labels.*.name, 'ready-to-deploy') ||
      github.event_name == 'push'
    outputs:
      cache-key: ${{ steps.cache.outputs.cache-hit }}
      build-hash: ${{ steps.build-hash.outputs.hash }}

    steps:
      - uses: actions/checkout@v4
        with:
          ref: ${{ github.event.pull_request.head.sha || github.ref }}

      - name: Setup Node.js with caching
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          check-latest: true
          cache: 'npm'

      # Enhanced npm caching
      - name: Cache node modules
        id: cache
        uses: actions/cache@v4
        with:
          path: |
            ~/.npm
            node_modules
            ~/.cache/Cypress
          key: ${{ runner.os }}-node-${{ hashFiles('**/package-lock.json') }}-${{ github.sha }}
          restore-keys: |
            ${{ runner.os }}-node-${{ hashFiles('**/package-lock.json') }}-
            ${{ runner.os }}-node-

      - name: Install dependencies (optimized)
        run: |
          npm install -g npm@${{ env.NPM_VERSION }}
          if [ "${{ steps.cache.outputs.cache-hit }}" != "true" ]; then
            npm ci --install-links
          else
            echo "Using cached node_modules"
          fi

      # Quality checks
      - name: Run ESLint
        run: npx eslint . --ext .js,.jsx,.ts,.tsx,.astro --no-cache

      - name: Check formatting
        run: npm run format:check

      - name: Type check
        run: npm run typecheck

      # Install Playwright browsers (cached)
      - name: Cache Playwright browsers
        uses: actions/cache@v4
        with:
          path: ~/.cache/ms-playwright
          key: ${{ runner.os }}-playwright-${{ hashFiles('**/package-lock.json') }}

      - name: Install Playwright browsers
        run: npx playwright install --with-deps

      # Build once and cache
      - name: Build site
        run: |
          echo "Building site..."
          npm run build
          echo "Build completed. Checking dist directory:"
          ls -la ${{ env.DIST_DIR }}
          echo "Total files in dist:"
          find ${{ env.DIST_DIR }} -type f | wc -l

      - name: Generate build hash
        id: build-hash
        run: |
          # Ensure dist directory exists and has content
          if [ ! -d "${{ env.DIST_DIR }}" ] || [ -z "$(ls -A ${{ env.DIST_DIR }})" ]; then
            echo "Error: Dist directory is empty or doesn't exist"
            exit 1
          fi

          # Generate comprehensive hash that includes ALL files that could affect build
          echo "=== Generating comprehensive build hash ==="

          # 1. Source files (expanded to include all relevant types)
          echo "Computing source files hash..."
          SOURCE_HASH=$(find src/ -type f \( \
            -name "*.astro" -o -name "*.ts" -o -name "*.tsx" -o -name "*.js" -o -name "*.jsx" \
            -o -name "*.md" -o -name "*.mdx" -o -name "*.json" -o -name "*.yaml" -o -name "*.yml" \
            -o -name "*.css" -o -name "*.scss" -o -name "*.sass" -o -name "*.less" \
            -o -name "*.vue" -o -name "*.svelte" -o -name "*.html" \
          \) -exec sha256sum {} \; 2>/dev/null | sort | sha256sum | cut -d' ' -f1)

          # 2. Configuration files that affect build
          echo "Computing configuration files hash..."
          CONFIG_HASH=$(find . -maxdepth 1 -type f \( \
            -name "astro.config.*" -o -name "vite.config.*" -o -name "tsconfig.json" \
            -o -name "package.json" -o -name "tailwind.config.*" -o -name "postcss.config.*" \
            -o -name ".env*" -o -name "*.config.js" -o -name "*.config.mjs" -o -name "*.config.ts" \
          \) -exec sha256sum {} \; 2>/dev/null | sort | sha256sum | cut -d' ' -f1)

          # 3. Public assets that get copied
          echo "Computing public assets hash..."
          if [ -d "public/" ]; then
            PUBLIC_HASH=$(find public/ -type f -exec sha256sum {} \; 2>/dev/null | sort | sha256sum | cut -d' ' -f1)
          else
            PUBLIC_HASH="no-public-dir"
          fi

          # 4. Build output hash
          echo "Computing dist files hash..."
          DIST_HASH=$(find ${{ env.DIST_DIR }} -type f -exec sha256sum {} \; | sort | sha256sum | cut -d' ' -f1)

          # 5. Git commit SHA for uniqueness
          COMMIT_SHA="${{ github.sha }}"

          # 6. Timestamp to ensure uniqueness for same commit (development aid)
          TIMESTAMP=$(date +%s)

          # Combine all hashes for unique build identifier
          BUILD_HASH=$(echo "${SOURCE_HASH}-${CONFIG_HASH}-${PUBLIC_HASH}-${DIST_HASH}-${COMMIT_SHA}-${TIMESTAMP}" | sha256sum | cut -d' ' -f1)

          # Validate hash is not empty
          if [ -z "$BUILD_HASH" ]; then
            echo "Error: Build hash is empty"
            exit 1
          fi

          echo "=== Build Hash Components ==="
          echo "Source files hash: $SOURCE_HASH"
          echo "Config files hash: $CONFIG_HASH" 
          echo "Public assets hash: $PUBLIC_HASH"
          echo "Dist output hash: $DIST_HASH"
          echo "Commit SHA: $COMMIT_SHA"
          echo "Timestamp: $TIMESTAMP"
          echo "=== Final Build Hash ==="
          echo "Generated build hash: $BUILD_HASH"
          echo "hash=$BUILD_HASH" >> $GITHUB_OUTPUT

      # Upload build artifacts for reuse
      - name: Upload build artifacts
        uses: actions/upload-artifact@v4
        with:
          name: dist-${{ steps.build-hash.outputs.hash }}
          path: ${{ env.DIST_DIR }}
          retention-days: 1

      - name: Debug artifact upload
        run: |
          echo "Uploaded artifact with name: dist-${{ steps.build-hash.outputs.hash }}"
          echo "Build hash: ${{ steps.build-hash.outputs.hash }}"
          echo "Artifact path: ${{ env.DIST_DIR }}"

      # Run Playwright tests on built site
      - name: Run Playwright tests
        run: npm run test || true
        env:
          CI: true

      - name: Upload test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: playwright-report-${{ github.run_id }}
          path: playwright-report/
          retention-days: 7

  # Security scan (uses cached dependencies)
  security-scan:
    needs: [build-and-test]
    runs-on: ubuntu-latest
    if: |
      contains(github.event.pull_request.labels.*.name, 'ready-to-test') || 
      contains(github.event.pull_request.labels.*.name, 'ready-to-deploy') ||
      github.event_name == 'push'

    steps:
      - uses: actions/checkout@v4

      - name: Run Trivy vulnerability scanner
        uses: aquasecurity/trivy-action@master
        with:
          scan-type: 'fs'
          scan-ref: '.'
          format: 'sarif'
          output: 'trivy-results.sarif'

  # Performance test (reuses build artifact)
  performance-test:
    needs: [build-and-test]
    runs-on: ubuntu-latest
    if: |
      contains(github.event.pull_request.labels.*.name, 'ready-to-test') || 
      contains(github.event.pull_request.labels.*.name, 'ready-to-deploy') ||
      github.event_name == 'push'

    steps:
      - uses: actions/checkout@v4

      - name: Debug job inputs
        run: |
          echo "Build hash from build-and-test job: ${{ needs.build-and-test.outputs.build-hash }}"
          echo "Expected artifact name: dist-${{ needs.build-and-test.outputs.build-hash }}"
          echo "Dist directory: ${{ env.DIST_DIR }}"

      - name: Setup Node.js with caching
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          check-latest: true
          cache: 'npm'

      # Restore cached dependencies
      - name: Restore node modules cache
        uses: actions/cache@v4
        with:
          path: |
            ~/.npm
            node_modules
          key: ${{ runner.os }}-node-${{ hashFiles('**/package-lock.json') }}-${{ github.sha }}
          restore-keys: |
            ${{ runner.os }}-node-${{ hashFiles('**/package-lock.json') }}-
            ${{ runner.os }}-node-

      - name: Install dependencies (from cache)
        run: npm ci --install-links

      # Download pre-built artifacts
      - name: Download build artifacts
        uses: actions/download-artifact@v4
        with:
          name: dist-${{ needs.build-and-test.outputs.build-hash }}
          path: ${{ env.DIST_DIR }}
        continue-on-error: true
        id: download-artifacts

      - name: Setup Node.js with caching (if needed)
        if: steps.download-artifacts.outcome == 'failure' || contains(github.event.pull_request.labels.*.name, 'ready-to-deploy') || github.ref == 'refs/heads/main'
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          check-latest: true
          cache: 'npm'

      - name: Force fresh build for ALL deployments
        if: steps.download-artifacts.outcome == 'failure' || contains(github.event.pull_request.labels.*.name, 'ready-to-deploy') || github.ref == 'refs/heads/main'
        run: |
          if [ "${{ github.ref }}" == "refs/heads/main" ]; then
            echo "Main branch detected - forcing fresh build to ensure latest code"
          elif [[ "${{ github.event.pull_request.labels.*.name }}" == *"ready-to-deploy"* ]]; then
            echo "PR deployment detected - forcing fresh build to ensure latest code"
          else
            echo "Artifacts not available, building locally..."
          fi
          npm install -g npm@${{ env.NPM_VERSION }}
          npm ci --install-links
          npm run build
          echo "Fresh build completed for commit: ${{ github.sha }}"

      - name: Verify dist directory
        run: |
          if [ ! -d "${{ env.DIST_DIR }}" ] || [ -z "$(ls -A ${{ env.DIST_DIR }})" ]; then
            echo "Error: Dist directory is empty or doesn't exist after build/download"
            exit 1
          fi
          echo "Dist directory contents:"
          ls -la ${{ env.DIST_DIR }}

      - name: Start preview server and wait for readiness
        run: |
          echo "Starting preview server in background..."
          npm run preview &
          SERVER_PID=$!
          echo "SERVER_PID=$SERVER_PID" >> $GITHUB_ENV
          echo "Server PID: $SERVER_PID"

          echo "Waiting for server to be ready..."
          for i in {1..30}; do
            if curl -f -s http://localhost:4321 > /dev/null 2>&1; then
              echo "✅ Server is ready after ${i} attempts"
              break
            fi
            if [ $i -eq 30 ]; then
              echo "❌ Server failed to start after 30 attempts"
              echo "Killing server process..."
              kill $SERVER_PID 2>/dev/null || true
              exit 1
            fi
            echo "Attempt $i/30: Server not ready yet, waiting 3 seconds..."
            sleep 3
          done

      - name: Run Lighthouse CI
        run: |
          npm install -g @lhci/cli@0.13.x
          lhci autorun --config=.lighthouserc.js || echo "Lighthouse CI completed with warnings"
        continue-on-error: true

      - name: Check bundle size (optional)
        run: npx bundlesize || echo "Bundlesize not configured, skipping..."
        continue-on-error: true

      - name: Cleanup preview server
        if: always()
        run: |
          if [ ! -z "$SERVER_PID" ]; then
            echo "Stopping preview server (PID: $SERVER_PID)..."
            kill $SERVER_PID 2>/dev/null || true
            sleep 2
            # Force kill if still running
            kill -9 $SERVER_PID 2>/dev/null || true
          fi

  # Release preparation (only when ready-to-deploy label is added)
  prepare-release:
    needs: [build-and-test, security-scan, performance-test]
    if: |
      contains(github.event.pull_request.labels.*.name, 'ready-to-deploy') ||
      (github.event_name == 'push' && github.ref == 'refs/heads/main')
    runs-on: ubuntu-latest
    outputs:
      new_version: ${{ steps.versioning.outputs.new_version }}
      release_id: ${{ steps.create_release.outputs.release_id }}

    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0
          ref: main

      # No need to rebuild - reuse artifacts
      - name: Download build artifacts
        uses: actions/download-artifact@v4
        with:
          name: dist-${{ needs.build-and-test.outputs.build-hash }}
          path: ${{ env.DIST_DIR }}
        continue-on-error: true
        id: download-artifacts

      - name: Setup Node.js with caching (if needed)
        if: steps.download-artifacts.outcome == 'failure'
        uses: actions/setup-node@v4
        with:
          node-version: ${{ env.NODE_VERSION }}
          check-latest: true
          cache: 'npm'

      - name: Fallback build if artifacts not available
        if: steps.download-artifacts.outcome == 'failure'
        run: |
          echo "Artifacts not available, building locally..."
          npm install -g npm@${{ env.NPM_VERSION }}
          npm ci --install-links
          npm run build

      - name: Verify dist directory
        run: |
          if [ ! -d "${{ env.DIST_DIR }}" ] || [ -z "$(ls -A ${{ env.DIST_DIR }})" ]; then
            echo "Error: Dist directory is empty or doesn't exist after build/download"
            exit 1
          fi

      - name: Determine version bump
        id: bump
        uses: actions/github-script@v7
        with:
          script: |
            let bump = 'patch';
            if (context.eventName === 'pull_request') {
              const labels = context.payload.pull_request.labels.map(l => l.name);
              if (labels.includes('major')) bump = 'major';
              else if (labels.includes('minor')) bump = 'minor';
            }
            core.setOutput('bump', bump);

      - name: Get latest version
        id: versioning
        run: |
          # Get all tags and sort them by version
          LATEST_TAG=$(git tag -l "v*" | sort -V | tail -n 1 || echo "v0.0.0")
          CURRENT_VERSION=${LATEST_TAG#v}

          # If no version exists, start with 0.0.0
          if [ -z "$CURRENT_VERSION" ]; then
            CURRENT_VERSION="0.0.0"
          fi

          IFS='.' read -r major minor patch <<< "$CURRENT_VERSION"

          case "${{ steps.bump.outputs.bump }}" in
            major)
              NEW_VERSION="$((major + 1)).0.0"
              ;;
            minor)
              NEW_VERSION="${major}.$((minor + 1)).0"
              ;;
            *)
              NEW_VERSION="${major}.${minor}.$((patch + 1))"
              ;;
          esac

          echo "new_version=$NEW_VERSION" >> $GITHUB_OUTPUT

      - name: Create Git Tag
        run: |
          git config --local user.email "github-actions[bot]@users.noreply.github.com"
          git config --local user.name "github-actions[bot]"
          git tag -a "v${{ steps.versioning.outputs.new_version }}" -m "Release v${{ steps.versioning.outputs.new_version }}"
          git push origin "v${{ steps.versioning.outputs.new_version }}"

      - name: Create Release
        id: create_release
        uses: actions/github-script@v7
        with:
          script: |
            const { owner, repo } = context.repo;
            const newVersion = '${{ steps.versioning.outputs.new_version }}';
            const tagName = `v${newVersion}`;

            try {
              // Try to get existing release
              const existingRelease = await github.rest.repos.getReleaseByTag({
                owner,
                repo,
                tag: tagName
              });
              
              // If release exists, update it with auto-generated notes
              const release = await github.rest.repos.updateRelease({
                owner,
                repo,
                release_id: existingRelease.data.id,
                name: `Release ${tagName}`,
                body: `Automated release ${tagName} with latest updates and improvements.`,
                draft: false,
                prerelease: false
              });
              
              core.setOutput('release_id', release.data.id);
            } catch (error) {
              if (error.status === 404) {
                // Release doesn't exist, create new one with auto-generated release notes
                const release = await github.rest.repos.createRelease({
                  owner,
                  repo,
                  tag_name: tagName,
                  name: `Release ${tagName}`,
                  body: `Automated release ${tagName}`,
                  draft: false,
                  prerelease: false,
                  generate_release_notes: true
                });
                
                core.setOutput('release_id', release.data.id);
              } else {
                throw error;
              }
            }

  # Deploy (reuses the same build artifacts)
  deploy:
    needs: [prepare-release, build-and-test]
    runs-on: ubuntu-latest
    environment: production
    if: |
      contains(github.event.pull_request.labels.*.name, 'ready-to-deploy') ||
      (github.event_name == 'push' && github.ref == 'refs/heads/main')

    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      # Use ONLY the validated artifacts from prepare-release - NO rebuilding
      - name: Download validated build artifacts
        uses: actions/download-artifact@v4
        with:
          name: dist-${{ needs.build-and-test.outputs.build-hash }}
          path: ${{ env.DIST_DIR }}
        id: download-artifacts

      - name: Verify artifacts were downloaded
        run: |
          if [ ! -d "${{ env.DIST_DIR }}" ] || [ -z "$(ls -A ${{ env.DIST_DIR }})" ]; then
            echo "❌ ERROR: Build artifacts not available from prepare-release job"
            echo "This indicates the prepare-release job failed or artifacts were not created"
            exit 1
          fi

          echo "✅ Successfully downloaded validated build artifacts"
          echo "=== DEPLOYMENT DEBUGGING INFORMATION ==="
          echo "Build hash used: ${{ needs.build-and-test.outputs.build-hash }}"
          echo "Commit SHA: ${{ github.sha }}"
          echo "Workflow run ID: ${{ github.run_id }}"
          echo "Event: ${{ github.event_name }}"
          echo "Ref: ${{ github.ref }}"

          echo "=== ARTIFACT DIRECTORY STRUCTURE ==="
          ls -la ${{ env.DIST_DIR }}
          echo ""

          echo "=== TOTAL FILE COUNT ==="
          TOTAL_FILES=$(find ${{ env.DIST_DIR }} -type f | wc -l)
          echo "Total files: $TOTAL_FILES"
          echo ""

          echo "=== FILE TYPES BREAKDOWN ==="
          find ${{ env.DIST_DIR }} -type f | grep -E '\.[^.]+$' | sed 's/.*\.//' | sort | uniq -c | sort -nr
          echo ""

          echo "=== KEY FILE CHECKSUMS (for deployment verification) ==="
          # Check key files that should change between deployments
          if [ -f "${{ env.DIST_DIR }}/index.html" ]; then
            echo "index.html: $(sha256sum ${{ env.DIST_DIR }}/index.html | cut -d' ' -f1)"
          fi

          if [ -d "${{ env.DIST_DIR }}/_astro" ]; then
            echo "=== _astro directory contents ==="
            ls -la ${{ env.DIST_DIR }}/_astro/ | head -10
          fi

          echo "=== RECENT FILE MODIFICATIONS ==="
          find ${{ env.DIST_DIR }} -type f -exec stat -c '%Y %n' {} \; | sort -nr | head -10 | while read timestamp file; do
            date -d "@$timestamp" '+%Y-%m-%d %H:%M:%S' | tr -d '\n'
            echo " $file"
          done

          echo ""
          echo "=== DEPLOYMENT READY - Proceeding to Cloudflare Pages ==="

      - name: Inject deployment metadata
        run: |
          echo "=== INJECTING DEPLOYMENT METADATA FOR CACHE BUSTING ==="

          # Create deployment metadata file
          cat > ${{ env.DIST_DIR }}/.deployment-meta.json << EOF
          {
            "deploymentId": "${{ github.run_id }}-${{ github.run_number }}",
            "commitSha": "${{ github.sha }}",
            "buildHash": "${{ needs.build-and-test.outputs.build-hash }}",
            "timestamp": "$(date -u +%Y-%m-%dT%H:%M:%SZ)",
            "branch": "${{ github.ref_name }}",
            "event": "${{ github.event_name }}"
          }
          EOF

          echo "Created deployment metadata:"
          cat ${{ env.DIST_DIR }}/.deployment-meta.json

          # Update any HTML files with deployment info (for cache busting)
          if [ -f "${{ env.DIST_DIR }}/index.html" ]; then
            # Add deployment info as a comment in index.html for cache busting
            sed -i "s|</head>|<!-- Deployment: ${{ github.run_id }}-${{ github.run_number }} at $(date -u +%Y-%m-%dT%H:%M:%SZ) -->\n</head>|" ${{ env.DIST_DIR }}/index.html
            echo "✅ Added deployment metadata to index.html"
          fi

          echo "=== FINAL FILE COUNT AFTER METADATA INJECTION ==="
          echo "Total files: $(find ${{ env.DIST_DIR }} -type f | wc -l)"

      - name: Deploy to Cloudflare Pages
        id: pages-deploy
        uses: cloudflare/wrangler-action@v3
        with:
          apiToken: ${{ secrets.CF_API_TOKEN }}
          accountId: ${{ secrets.CF_ACCOUNT_ID }}
          command: pages deploy ${{ env.DIST_DIR }} --project-name=${{ env.PROJECT_NAME }} --branch=main
        env:
          # Set environment variables for deployment
          SITE_URL: ${{ env.SITE_URL }}
          DEV_URL: ${{ env.DEV_URL }}
          DEV_PORT: ${{ env.DEV_PORT }}
          GISCUS_REPO: ${{ secrets.GISCUS_REPO }}
          GISCUS_REPO_ID: ${{ secrets.GISCUS_REPO_ID }}
          GISCUS_CATEGORY: ${{ secrets.GISCUS_CATEGORY }}
          GISCUS_CATEGORY_ID: ${{ secrets.GISCUS_CATEGORY_ID }}
          RATE_LIMIT_REQUESTS: ${{ env.RATE_LIMIT_REQUESTS }}
          RATE_LIMIT_WINDOW: ${{ env.RATE_LIMIT_WINDOW }}

      - name: Configure KV Namespaces (if needed)
        if: success()
        run: |
          echo "Configuring KV namespace bindings..."

          # Check if the KV namespaces are properly bound to the project
          # The wrangler-action doesn't handle KV bindings automatically like pages-action did
          # We need to ensure they're configured in the Cloudflare dashboard or via API

          export CLOUDFLARE_API_TOKEN="${{ secrets.CF_API_TOKEN }}"
          export CLOUDFLARE_ACCOUNT_ID="${{ secrets.CF_ACCOUNT_ID }}"

          # Update project with KV namespace bindings
          echo "Updating project KV namespace configuration..."
          curl -X PATCH "https://api.cloudflare.com/client/v4/accounts/${{ secrets.CF_ACCOUNT_ID }}/pages/projects/${{ env.PROJECT_NAME }}" \
            -H "Authorization: Bearer ${{ secrets.CF_API_TOKEN }}" \
            -H "Content-Type: application/json" \
            --data '{
              "deployment_configs": {
                "production": {
                  "kv_namespaces": {
                    "VISIT_COUNTS": {
                      "namespace_id": "${{ secrets.KV_VISIT_COUNTS_ID }}"
                    },
                    "LIKES": {
                      "namespace_id": "${{ secrets.KV_LIKES_ID }}"
                    }
                  }
                },
                "preview": {
                  "kv_namespaces": {
                    "VISIT_COUNTS": {
                      "namespace_id": "${{ secrets.KV_VISIT_COUNTS_ID }}"
                    },
                    "LIKES": {
                      "namespace_id": "${{ secrets.KV_LIKES_ID }}"
                    }
                  }
                }
              }
            }'

      - name: Debug Secrets and Configuration
        if: always()
        run: |
          echo "=== DEBUGGING SECRETS AND CONFIGURATION ==="
          echo "Checking if required secrets are available..."

          # Check if secrets are set (without exposing their values)
          if [ -z "${{ secrets.CF_API_TOKEN }}" ]; then
            echo "❌ CF_API_TOKEN secret is not set"
          else
            echo "✅ CF_API_TOKEN secret is set (length: ${#CF_API_TOKEN})"
          fi

          if [ -z "${{ secrets.CF_ACCOUNT_ID }}" ]; then
            echo "❌ CF_ACCOUNT_ID secret is not set"
          else
            echo "✅ CF_ACCOUNT_ID secret is set"
          fi

          if [ -z "${{ secrets.KV_VISIT_COUNTS_ID }}" ]; then
            echo "❌ KV_VISIT_COUNTS_ID secret is not set"
          else
            echo "✅ KV_VISIT_COUNTS_ID secret is set"
          fi

          if [ -z "${{ secrets.KV_LIKES_ID }}" ]; then
            echo "❌ KV_LIKES_ID secret is not set"
          else
            echo "✅ KV_LIKES_ID secret is set"
          fi

          echo ""
          echo "=== PROJECT CONFIGURATION ==="
          echo "Project Name: ${{ env.PROJECT_NAME }}"
          echo "Directory: ${{ env.DIST_DIR }}"
          echo "Wrangler Version: ${{ env.WRANGLER_VERSION }}"
          echo ""

          # Verify dist directory exists and has content
          if [ -d "${{ env.DIST_DIR }}" ]; then
            echo "✅ Dist directory exists"
            echo "File count: $(find ${{ env.DIST_DIR }} -type f | wc -l)"
            echo "Directory size: $(du -sh ${{ env.DIST_DIR }} | cut -f1)"
          else
            echo "❌ Dist directory does not exist!"
            exit 1
          fi
        env:
          CF_API_TOKEN: ${{ secrets.CF_API_TOKEN }}

      - name: Debug Cloudflare Pages Action
        if: always()
        run: |
          echo "=== CLOUDFLARE PAGES ACTION DEBUGGING ==="
          echo "Deployment step outcome: ${{ steps.pages-deploy.outcome }}"
          echo "Deployment step conclusion: ${{ steps.pages-deploy.conclusion }}"
          echo ""

          # Check if the step outputs are available
          echo "=== DEPLOYMENT OUTPUTS ==="
          echo "Deployment URL: ${{ steps.pages-deploy.outputs.url }}"
          echo "Deployment ID: ${{ steps.pages-deploy.outputs.id }}"
          echo "Environment: ${{ steps.pages-deploy.outputs.environment }}"
          echo "Alias: ${{ steps.pages-deploy.outputs.alias }}"
          echo ""

          # If deployment failed, try to get more information
          if [ "${{ steps.pages-deploy.outcome }}" = "failure" ]; then
            echo "❌ CLOUDFLARE PAGES ACTION FAILED!"
            echo "Checking recent deployments via API..."
            
            # Get recent deployment info
            LATEST_DEPLOYMENT=$(curl -s -X GET \
              "https://api.cloudflare.com/client/v4/accounts/${{ secrets.CF_ACCOUNT_ID }}/pages/projects/${{ env.PROJECT_NAME }}/deployments" \
              -H "Authorization: Bearer ${{ secrets.CF_API_TOKEN }}" \
              -H "Content-Type: application/json" | jq -r '.result[0]')
            
            if [ "$LATEST_DEPLOYMENT" != "null" ]; then
              echo "Latest deployment info:"
              echo "$LATEST_DEPLOYMENT" | jq .
            fi
          fi

      - name: Verify Deployment Success
        if: steps.pages-deploy.outcome == 'success' || success()
        run: |
          echo "=== VERIFYING DEPLOYMENT SUCCESS ==="

          # Wait for deployment to propagate
          echo "Waiting 15 seconds for deployment propagation..."
          sleep 15

          # Try to determine the deployment URL
          if [ -n "${{ steps.pages-deploy.outputs.url }}" ]; then
            DEPLOYMENT_URL="${{ steps.pages-deploy.outputs.url }}"
            echo "Using GitHub Action output URL: $DEPLOYMENT_URL"
          else
            # For manual deployments, construct the URL
            DEPLOYMENT_URL="https://blog.radaideh.info"
            echo "Using production domain: $DEPLOYMENT_URL"
          fi

          # Test the deployment
          echo "Testing deployment at: $DEPLOYMENT_URL"

          MAX_RETRIES=3
          RETRY_COUNT=0

          while [ $RETRY_COUNT -lt $MAX_RETRIES ]; do
            HTTP_STATUS=$(curl -s -o /dev/null -w "%{http_code}" "$DEPLOYMENT_URL")
            
            if [ "$HTTP_STATUS" = "200" ]; then
              echo "✅ Site is accessible (HTTP $HTTP_STATUS)"
              break
            else
              echo "⚠️ Site returned HTTP $HTTP_STATUS"
              RETRY_COUNT=$((RETRY_COUNT + 1))
              if [ $RETRY_COUNT -lt $MAX_RETRIES ]; then
                echo "Retrying in 10 seconds..."
                sleep 10
              fi
            fi
          done

          echo "Deployment verification completed."

      - name: Create KV Namespaces (if needed)
        if: success()
        run: |
          echo "Ensuring KV namespaces exist..."
          export CLOUDFLARE_API_TOKEN="${{ secrets.CF_API_TOKEN }}"
          export CLOUDFLARE_ACCOUNT_ID="${{ secrets.CF_ACCOUNT_ID }}"

          # Check if namespaces exist, create if not
          for ns in VISIT_COUNTS LIKES; do
            echo "Checking KV namespace: $ns"
            npx wrangler@${{ env.WRANGLER_VERSION }} kv:namespace list | grep -q "$ns" || {
              echo "Creating KV namespace: $ns"
              npx wrangler@${{ env.WRANGLER_VERSION }} kv:namespace create $ns || true
            }
          done

      - name: Update Deployment Status
        if: always()
        uses: actions/github-script@v7
        with:
          script: |
            const { owner, repo } = context.repo;
            const deployment = await github.rest.repos.createDeployment({
              owner,
              repo,
              ref: context.sha,
              environment: '${{ env.DEPLOYMENT_ENV }}',
              auto_merge: false,
              required_contexts: [],
              description: '${{ env.DEPLOYMENT_ENV }} Deployment'
            });

            const status = '${{ job.status }}' === 'success' ? 'success' : 'failure';
            await github.rest.repos.createDeploymentStatus({
              owner,
              repo,
              deployment_id: deployment.data.id,
              state: status,
              environment: '${{ env.DEPLOYMENT_ENV }}',
              environment_url: 'https://${{ env.CUSTOM_DOMAIN }}',
              description: status === 'success' ? 'Deployment successful' : 'Deployment failed',
              log_url: `https://github.com/${owner}/${repo}/actions/runs/${context.runId}`
            });

      - name: Update PR Labels
        if: success() && github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            // Remove ready-to-deploy label and add deployed label
            try {
              await github.rest.issues.removeLabel({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: context.issue.number,
                name: 'ready-to-deploy'
              });
            } catch (error) {
              console.log('ready-to-deploy label not found or already removed');
            }

            await github.rest.issues.addLabels({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
              labels: ['deployed']
            });

      - name: Notify on Failure
        if: failure()
        uses: actions/github-script@v7
        with:
          script: |
            const { owner, repo } = context.repo;
            await github.rest.issues.create({
              owner,
              repo,
              title: '🚨 Deployment Failed',
              body: `Deployment failed in run [#${context.runNumber}](https://github.com/${owner}/${repo}/actions/runs/${context.runId})\n\nCommit: ${context.sha}\nBranch: ${context.ref}\n\nPlease check the logs and fix the issues before retrying.`,
              labels: ['deployment', 'bug']
            });

  # Cleanup artifacts after successful deployment
  cleanup:
    needs: [deploy]
    runs-on: ubuntu-latest
    if: always()
    permissions:
      actions: write
      contents: read

    steps:
      - name: Cleanup old artifacts
        uses: actions/github-script@v7
        continue-on-error: true
        with:
          script: |
            try {
              console.log('Fetching artifacts for cleanup...');
              const artifacts = await github.rest.actions.listWorkflowRunArtifacts({
                owner: context.repo.owner,
                repo: context.repo.repo,
                run_id: context.runId,
              });

              console.log(`Found ${artifacts.data.artifacts.length} artifacts`);

              let deletedCount = 0;
              for (const artifact of artifacts.data.artifacts) {
                if (artifact.name.startsWith('dist-')) {
                  try {
                    console.log(`Deleting artifact: ${artifact.name} (ID: ${artifact.id})`);
                    await github.rest.actions.deleteArtifact({
                      owner: context.repo.owner,
                      repo: context.repo.repo,
                      artifact_id: artifact.id,
                    });
                    deletedCount++;
                    console.log(`✅ Successfully deleted artifact: ${artifact.name}`);
                  } catch (deleteError) {
                    console.log(`⚠️ Failed to delete artifact ${artifact.name}: ${deleteError.message}`);
                    // Continue with other artifacts even if one fails
                  }
                }
              }
              
              console.log(`🧹 Cleanup completed: ${deletedCount} artifacts deleted`);
            } catch (error) {
              console.log(`❌ Cleanup failed: ${error.message}`);
              // Don't fail the workflow if cleanup fails
            }
